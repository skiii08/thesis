\chapter{提案手法：GLRモデル}
\label{sec:glr_structure}

\section{設計動機と全体構成}

本研究が提案する
GLR（Group-wise Linear Regression with Regularization）は、
映画評価を構成する要因を意味的に整理し、
予測値を複数の寄与として明示的に分解するための線形回帰モデルである。

本章では、その設計とモデル構造を具体的に説明する。
まず線形モデルとしての基本構造を示し、
次に4系列による寄与分解の枠組みを述べる。
その後、特徴量設計とレビュー情報の抽出方法を示し、
最後に、寄与分解を安定化するための正則化戦略を説明する。

\section{基本設計方針}

\subsection{線形モデルとしての設計}
\label{subsec:linear_design}

推薦理由の理解可能性は、推薦システムの信頼性に直結する重要な要素である。
しかし、近年主流の深層学習やMatrix Factorizationでは、
予測根拠が潜在空間や非線形変換の内部に埋もれやすく、
利用者がその内容を直接解釈することは困難である。

本研究では、線形回帰を基盤とするモデル構造を採用する。
線形モデルでは、予測値が入力特徴量と重みの積和として表現されるため、
各特徴が予測にどの程度寄与したかを数学的に一意に定義できる。

ここで寄与とは、各特徴グループが予測値に与える影響の大きさを意味し、
重みベクトルと特徴ベクトルの内積として計算される。

本研究で用いる線形モデルの予測式は、以下のように表される：

\begin{equation}
\label{eq:linear_base_y}
\hat{y} = b + \sum_{g=1}^{N} \mathbf{w}_g^\top \mathbf{x}_g
\end{equation}

ここで、$\hat{y}$ は予測評価値、$b$ はバイアス項、$\mathbf{w}_g$ は特徴グループ $g$ に対応する重みベクトル、$\mathbf{x}_g$ は同グループに属する特徴ベクトルである。
$N$ は特徴量を意味的に分割した特徴グループの総数を表し、
本研究では得られたメタデータを網羅的に整理した結果、$N=17$ となった
（詳細は\ref{subsec:features}節および表\ref{tab:feature_groups}）。

この構造により、予測値は各グループの寄与の和として表現される。
各寄与は重みベクトルと特徴ベクトルの内積として決定論的に算出されるため、
同一入力に対しては常に同一の予測結果が得られる。




\subsection{4系列による予測分解}
\label{subsec:four_stream}

本研究では、映画評価に影響する要因を、
User・Movie・Interaction・Review の
4系列として整理する。

ここで、系列は複数の特徴量をまとめて解釈するための上位概念であり、
実際のモデルでは、各系列は複数の特徴グループから構成される。
特徴グループは、系列を構成する具体的な特徴集合であり、
全17グループがいずれかの系列に属する。

User系列はユーザー固有の評価傾向を、
Movie系列は映画そのものの属性を表す。
Interaction系列はユーザー特徴と映画特徴の組み合わせから得られる関係性を、
Review系列は、個別のレビューに含まれる評価内容を表す。


\eqref{eq:linear_base_y}において、17の特徴グループを4系列に整理すると、予測式は以下のように系列単位で表現できる：

\begin{equation}
\label{eq:four_stream}  
\begin{aligned}
\hat{y} = b
&+ \underbrace{\sum_{g \in \text{User}} \mathbf{w}_g^\top \mathbf{x}_g}_{\text{User寄与}}
+ \underbrace{\sum_{g \in \text{Movie}} \mathbf{w}_g^\top \mathbf{x}_g}_{\text{Movie寄与}} \\
&+ \underbrace{\sum_{g \in \text{Interaction}} \mathbf{w}_g^\top \mathbf{x}_g}_{\text{Interaction寄与}}
+ \underbrace{\sum_{g \in \text{Review}} \mathbf{w}_g^\top \mathbf{x}_g}_{\text{Review寄与}}
\end{aligned}
\end{equation}

この4系列構造により、
予測は例えば「User: +1.2, Movie: +0.3, Interaction: -0.8, Review: +0.1」のように、
系列ごとの異なる寄与の和として表現される。




\section{データセットと特徴量設計}
\label{sec:dataset}

\subsection{データセット概要}
\label{subsec:dataset_overview}

本研究では、IEEE DataPortで公開されているIMDbベースの映画レビューデータセットに加え、TMDb APIから取得した映画メタデータを統合したデータを使用する。データセットの基本統計を表\ref{tab:dataset_stats}に示す。

\begin{table}[H]
\centering
\caption{データセット統計}
\label{tab:dataset_stats}
\resizebox{\textwidth}{!}{
\begin{tabular}{ll}
\toprule
項目 & 値 \\
\midrule
ユーザー数 & 735名 \\
映画数 & 1,247作品 \\
レビュー数（総計） & 36,003件 \\
評価範囲（生データ） & 1--10（整数値） \\
評価範囲（正規化後） & $-2.5 \sim +2.5$ \\
Train / Val / Test 分割（レビュー単位）& 70\% / 12\% / 18\%（25,202 / 4,320 / 6,481件） \\
\bottomrule
\end{tabular}
}
\end{table}

なお本研究ではcold-start問題は扱わず、
既存ユーザーが未視聴の映画を評価する状況を想定する。
そのため、ユーザー単位で分割せず、
レビューをランダムにTrain / Validation / Testに分割した。

\paragraph{ターゲット変数の正規化}

本研究では、ユーザーごとの評価尺度の差を補正するため、
評価値（1–10）をユーザー内で Z-score 正規化した値を
予測ターゲットとして用いる：
正規化は以下の式で行う：

\begin{equation}
r'_{ui} = \frac{r_{ui} - \mu_u}{\sigma_u}
\end{equation}

ここで、$r_{ui}$はユーザー$u$が映画$i$につけた評価、
$\mu_u$と$\sigma_u$はユーザー$u$の評価の平均と標準偏差である。
なお、$\mu_u$および$\sigma_u$は学習データ内のユーザー履歴のみから算出し、
検証・テストデータは参照しない。

予測結果は、
$\hat{r}_{ui} = \hat{r}'_{ui} \cdot \sigma_u + \mu_u$
として逆正規化し、
元の評価スケールで解釈できる。





\subsection{LLMによるレビュー情報の抽出}
\label{subsec:llm}

前節で示した4系列のうち、User系列およびReview系列は、
自由記述であるレビュー本文に基づいて構成される。
しかし、レビュー全文をそのままモデルに入力することは、
線形モデルにおける寄与解釈や系列分解の観点から適切ではない。

そこで本研究では、レビュー本文を直接扱うのではなく、
映画評価における解釈可能な観点
（評価対象・感情傾向・注目要素）へと分解した
中間表現として整理することを目的とする。
この設計により、テキスト由来の情報を
GLRの線形構造に適した形で取り込むことが可能となる。

\paragraph{抽出手順}

各レビュー本文を文単位に分割し、
意味的に自己完結した文のみを対象として処理を行う。
これは、単一の文が特定の評価観点や感情を比較的明確に含むことが多く、
後続の集約処理において解釈の一貫性を保ちやすいためである。

各文に対しては、大規模言語モデル（GPT-4o mini）を用い、
映画批評において一般的に用いられる評価観点に基づき事前に定義した
トピックカテゴリ（19種）、
感情スコア（1--5）、
言及された人物名および属性タグを抽出する。
プロンプトには各カテゴリの定義と境界条件を明示し、
抽出結果のばらつきを抑えるよう設計している。

\paragraph{抽出結果の集約}
トピック別の言及頻度や感情の平均値として集約され、
Z-score正規化を施した上で数値特徴へと変換される。
ユーザー単位に集約された特徴はUser系列として、
個別レビュー単位の特徴はReview系列として用いられ、予測に寄与する。

\paragraph{抽出結果の妥当性確認}
なお本研究の主眼は、
このように整理されたレビュー由来特徴が
GLRにおける寄与分解および予測にどのような影響を与えるかにあり、
抽出結果そのものの精度検証は対象外とする。

ただし、抽出結果の妥当性を確認するため、
ランダムに抽出した約100レビューについて著者による目視確認を実施した。
その結果、トピック分類の妥当性は概ね85\%程度であり、
評価観点や感情傾向を実用上十分な精度で捉えていることを確認した。
また、抽出されたトピック分布が極端に偏っていないことも確認しており、
抽出精度が分析結果を著しく歪めるレベルではないと判断した。



\subsection{特徴量グループの構成}
\label{subsec:features}

前節までで示した線形モデルおよび4系列構造に基づき、
本研究では全1,988次元の特徴量を、17の特徴グループとして設計した。
各特徴グループは、予測式において独立した重みベクトルを持つ特徴集合として定義され、
いずれかの系列に対応づけられる。

表\ref{tab:feature_groups}に、
各特徴グループの内容に加え、それぞれが属する系列を示す。

\begin{table}[H]
\centering
\caption{特徴量グループの構成}
\label{tab:feature_groups}
\resizebox{\textwidth}{!}{
\begin{tabular}{llll}
\toprule
グループ名 & 系列 & 次元数 & 内容 \\
\midrule
user\_aspect\_zscore      & User        & 18  & 各トピックへの関心傾向 \\
user\_aspect\_sentiment  & User        & 18  & 各トピックに対する感情平均 \\
user\_stats               & User        & 5   & レビュー数・平均・分散などの統計 \\
user\_fav\_actor          & User        & 300 & 好きな俳優の埋め込み表現 \\
user\_fav\_director       & User        & 300 & 好きな監督の埋め込み表現 \\
user\_genre               & User        & 38  & ジャンル嗜好特徴 \\
user\_behavior            & User        & 5   & 行動特性（活動期間・頻度など） \\
movie\_genre              & Movie       & 19  & 映画ジャンル \\
movie\_actor              & Movie       & 300 & 映画俳優の埋め込み表現 \\
movie\_director           & Movie       & 300 & 映画監督の埋め込み表現 \\
movie\_keyword            & Movie       & 300 & 映画キーワードの埋め込み表現 \\
movie\_basic              & Movie       & 2   & 公開年・上映時間 \\
movie\_tags               & Movie       & 263 & 映画タグ特徴 \\
movie\_review\_agg        & Movie       & 18  & レビュー由来のトピック別集約値 \\
review\_aspects           & Review      & 18  & 各トピック別注目度 \\
review\_person            & Review      & 4   & 人物注目度 \\
interaction               & Interaction & 80  & UserとMovieの交差特徴 \\
\bottomrule
\end{tabular}
}
\end{table}

各特徴グループは、前節で定義した4系列のいずれかに対応づけられている。
この対応関係により、各特徴グループの寄与は系列単位で集約して解釈することが可能となる。

\paragraph{特徴量設計の補足}

いくつかの特徴グループについて、設計上の補足を述べる。

\textbf{埋め込み表現}（user\_fav\_actor、movie\_actor など）：
俳優名・監督名・キーワードといった高次元カテゴリ変数を、
意味的な距離関係を保持した連続ベクトルとして表現するために導入した。
本研究では、メタデータに含まれる固有名詞を
後に解釈可能な形で保持することを重視し、
PCA 等による次元削減は行わず、
FastText による 300 次元の埋め込みをそのまま用いている。
その結果、Movie 系列は 1,200 次元以上と高次元になるが、
これは設計上の意図に基づくものである。

\textbf{User 系列と Review 系列}：
いずれもレビュー本文から抽出された情報に基づく特徴を含むが、
集約の単位が異なる。
User 系列は複数レビューを集約することで
ユーザー全体の評価傾向を表すのに対し、
Review 系列は特定の映画に対する
個別レビューの評価内容を表現する。
この違いにより、
User 系列はユーザー単位で共通に用いられ、
Review 系列はレビュー単位で異なる特徴として予測に寄与する。

\textbf{Interaction 特徴}：
User 系列および Movie 系列の情報のみでは表現しきれない、
両者の組み合わせに固有の関係性を捉えるために導入した。
具体的には、
ユーザーの嗜好表現と映画の属性表現の対応関係や類似度などを
派生的な特徴として構成し、
「このユーザーがこの映画を評価する場合」に特有の傾向を
明示的に表現することを目的としている。



\section{損失関数}
\label{sec:objective}

\subsection{損失関数の設計方針}
\label{subsec:objective_design}

GLRは、17の特徴グループを
4系列（User、Movie、Interaction、Review）に集約して寄与を解釈する線形モデルである。
正則化は主にグループ単位で作用する。

予測誤差のみを最小化する学習では、
高次元性とグループ構造に起因して以下の設計上の課題が生じやすい：

\begin{description}
\item[\textbf{課題1：系列寄与の分離性の低下}] 
異なる系列が同様の情報を表現すると、系列ごとの説明が曖昧になる。

\item[\textbf{課題2：グループ内の重み集中}] 
高次元グループにおいて、一部の次元に重みが集中すると、
寄与構造が不安定化する。

\item[\textbf{課題3：Movie系列の相対的支配}] 
Movie系列（1,200次元以上）の総寄与が相対的に大きくなり、他系列の寄与が弱まる。
\end{description}

本研究では、これらに対応する正則化項を導入し、予測精度と寄与分解の安定性を両立する。
表\ref{tab:regularization_correspondence}に各課題と正則化項の対応を示す。

\begin{table}[h]
\centering
\caption{観測される課題と正則化項の対応関係}
\label{tab:regularization_correspondence}
\begin{tabular}{lll}
\hline
課題 & 正則化項 & 目的 \\
\hline
系列寄与の役割混在 & グループ間相関抑制 & 系列の分離性確保 \\
グループ内の重み集中 & グループ内分散抑制 & 重みの平滑化 \\
Movie系列の相対的支配 & Movie系列への抑制 & 系列間寄与のバランス調整 \\
\hline
\end{tabular}
\end{table}



\subsection{基本的な学習安定化：L2正則化}
\label{subsec:l2_regularization}

全特徴次元に一律のL2正則化を適用する：

\begin{equation}
\mathcal{L}_{\text{L2}} = \lambda_{\text{L2}} \lVert \mathbf{w} \rVert_2^2 = \lambda_{\text{L2}} \sum_{j=1}^{D} w_j^2
\end{equation}

ここで、$D$は全特徴次元数、$\mathbf{w}$は全重みベクトルである。
実装上は全次元に一律の正則化を適用しており、後述のグループ表記は説明上の集約である。
L2 正則化は、主として過学習を防ぐための
基礎的な安定化手段として位置づけられ、
系列間の役割分離や寄与構造の制御は、
後続の正則化項によって担われる。

グループごとに異なる係数を設定する戦略も検討したが、
本研究の実験条件下では、
一律係数を用いた設定が
解釈性指標（Permutation 法による $\rho$）の観測値において
相対的に安定していたため、本設定を採用した。





\subsection{課題1への対応：グループ間相関抑制}
\label{subsec:inter_group_correlation}

4系列による寄与分解では、
異なる特徴グループが
類似した方向の寄与を担うと、
系列ごとの寄与が分離しにくくなるという課題がある。
本研究ではこれに対し、
グループ間の重みの類似度に基づく
補助的な正則化項を導入する。

具体的には、
グループ $g$ および $h$ に属する重みベクトル
$\mathbf{w}_g, \mathbf{w}_h$ を
それぞれ平均 0、分散 1 に標準化し、
両者の Pearson 相関係数に基づく類似度指標を算出する。
本研究では、
この相関の二乗和を罰則として加える：

\begin{equation}
\mathcal{L}_{\text{corr}}
=
\lambda_{\text{corr}}
\sum_{g<h}
\text{Corr}(\mathbf{w}_g, \mathbf{w}_h)^2
\end{equation}

ここで $\text{Corr}(\mathbf{w}_g, \mathbf{w}_h)$ は、
標準化後の重みベクトル間の
方向的一致度を表す指標であり、
値が大きいほど、
異なるグループが
類似した寄与構造を持つことを意味する。
相関を二乗することで、
符号に依らず方向の一致そのものを罰する。

なお、
グループ間で次元数が異なる場合には、
共通の次元数（短い方の次元数）に基づき、
各重みベクトルの部分ベクトルを用いて
近似的に相関指標を算出している。
本正則化は、
特徴グループ間の統計的独立性を
仮定または保証するものではなく、
系列寄与の分離を
学習過程において緩やかに誘導するための
経験的な補助項として位置づけられる。



\subsection{課題2への対応：グループ内分散抑制}
\label{subsec:intra_group_variance}

高次元な特徴グループでは、
一部の次元にのみ重みが集中すると、
グループ全体としての寄与構造が
学習条件に依存して変動しやすくなる。
本研究ではこれに対し、
グループ内の重みのばらつきに基づく
補助的な正則化項を導入する。

具体的には、
各グループ $g$ に属する重みベクトル
$\mathbf{w}_g$ の分散を計算し、
その総和を罰則として加える：

\begin{equation}
\mathcal{L}_{\text{var}}
=
\lambda_{\text{var}}
\sum_{g=1}^{G}
\mathrm{Var}(\mathbf{w}_g)
\end{equation}

ここで $G$ は特徴グループの総数を表し、
$g$ は各特徴グループのインデックスである。
$\mathrm{Var}(\mathbf{w}_g)$ は、
グループ $g$ に属する重みの分散を表し、
値が大きいほど、
一部の次元への重み集中を含む
グループ内の寄与の偏りが大きいことを意味する。
本正則化は、
グループ内で極端な重み集中が生じることを抑制し、
高次元グループにおける
寄与構造の過度な偏りを
緩和することを目的とする。




\subsection{課題3への対応：Movie 系列への選択的抑制}
\label{subsec:movie_suppression}

Movie 系列は高次元であり、
通常の L2 正則化のみを用いた場合、
その総寄与が相対的に大きくなりやすい。
この結果、
User 系列をはじめとする他系列の寄与が弱まる傾向が確認された。

そこで本研究では、
Movie 系列に属する重みにのみ
選択的に L1 正則化を課す：

\begin{equation}
\mathcal{L}_{\text{movie}}
=
\lambda_{\text{movie}}
\left\| \mathbf{w}_{\text{Movie}} \right\|_1
=
\lambda_{\text{movie}}
\sum_{j=1}^{D_{\text{Movie}}}
\left| w^{(\text{Movie})}_j \right|
\end{equation}




ここで，
$\mathbf{w}_{\text{Movie}}$ は Movie 系列に属する全特徴次元の重みを表し，
本正則化は Movie 系列にのみ選択的に適用される。
$D_{\text{Movie}}$ は Movie 系列に属する特徴次元数，
$w^{(\text{Movie})}_j$ は Movie 系列の $j$ 番目の重みを表す。


本正則化は、
Movie 系列における個々の特徴を選択的に削除することを意図したものではなく、
高次元な Movie 系列全体の寄与が過度に大きくなることを抑制し、
系列間の寄与バランスを調整するために導入した。


\subsection{最終的な損失関数}
\label{subsec:final_objective}

最終的な損失関数は、
予測誤差の最小化を主目的とし、
寄与分解の安定性および系列間バランスを調整する
各正則化項を加えた次式で定式化される：


\begin{equation}
\mathcal{L}_{\text{total}}
=
\mathcal{L}_{\text{pred}}
+
\mathcal{L}_{\text{L2}}
+
\mathcal{L}_{\text{corr}}
+
\mathcal{L}_{\text{var}}
+
\mathcal{L}_{\text{movie}}
\end{equation}


ここで、
$\mathcal{L}_{\text{pred}}$ は予測性能を規定する主損失である。

これらの正則化項は、
予測性能を直接最適化するものではなく、
系列間の役割分離、寄与構造の安定化、
および高次元系列による支配の抑制といった
設計上必要なことを学習過程に反映させるために導入されている。

